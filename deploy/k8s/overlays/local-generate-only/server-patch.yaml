# deploy/k8s/overlays/local-generate-only/api-patch.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: server
  namespace: llm
spec:
  template:
    spec:
      containers:
        - name: server
          env:
            # Make the kind demo runnable
            - name: MODEL_LOAD_MODE
              value: "lazy"   # consider "eager" for deterministic demos
            - name: REQUIRE_MODEL_READY
              value: "0"      # consider "1" if MODEL_LOAD_MODE="eager"

            # Capabilities + routing policy comes from MODELS_YAML
            - name: MODELS_YAML
              value: "/app/models/models.yaml"

          volumeMounts:
            # keep the base mount explicit (avoid list-merge surprises)
            - name: llm-config
              mountPath: /app/config
              readOnly: true

            - name: llm-models
              mountPath: /app/models
              readOnly: true

      volumes:
        - name: llm-models
          configMap:
            name: llm-models
            items:
              - key: models.yaml
                path: models.yaml