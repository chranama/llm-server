# eval/pyproject.toml
[project]
name = "llm_eval"
version = "0.1.0"
description = "Evaluation and research toolkit for llm-server"
requires-python = "==3.12.*"

dependencies = [
  # HTTP + API interaction
  "httpx>=0.27",

  # Dataset handling
  "datasets>=2.21",

  # Schema validation / metrics
  "jsonschema>=4.21,<5.0",

  # Reporting / analytics
  "pandas>=2.2",
  "numpy>=1.26",

  # CLI / config
  "python-dotenv>=1.0.0",
  "pydantic-settings>=2.0",
  "llm-contracts @ file:../contracts",
]

[project.scripts]
eval = "llm_eval.cli:main"

[project.optional-dependencies]
# Heavier dataset deps (only needed for certain dataset adapters)
datasets = [
  # Needed for Voxel51/scanned_receipts loader:
  # `from fiftyone.utils.huggingface import load_from_hub`
  "fiftyone>=1.0.0",
]

test = [
  "pytest>=8",
  "pytest-asyncio>=0.23",
  "pytest-cov>=5",
  "coverage>=7",
]

lint = [
  "ruff>=0.5",
  "black>=24",
]

viz = [
  "matplotlib>=3.9",
  "seaborn>=0.13",
]

# Convenience: install everything commonly used in this module
all = [
  "llm_eval[datasets,test,lint,viz]",
]

[build-system]
requires = ["setuptools>=68", "wheel"]
build-backend = "setuptools.build_meta"

[tool.setuptools.packages.find]
where = ["src"]
include = ["llm_eval*"]
exclude = ["tests*"]

[tool.setuptools.package-data]
llm_eval = ["**/*.yaml", "**/*.json"]

[tool.pytest.ini_options]
addopts = "-q --cov=llm_eval --cov-report=term-missing"
testpaths = ["tests"]
asyncio_mode = "auto"